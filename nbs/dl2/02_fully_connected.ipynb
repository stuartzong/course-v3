{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The forward and backward passes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from exp.nb_01 import *\n",
    "\n",
    "def get_data():\n",
    "    path = datasets.download_data(MNIST_URL, ext='.gz')\n",
    "    with gzip.open(path, 'rb') as f:\n",
    "        ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding='latin-1')\n",
    "    return map(tensor, (x_train,y_train,x_valid,y_valid))\n",
    "\n",
    "def normalize(x, m, s): \n",
    "    return (x-m)/s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,y_train,x_valid,y_valid = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.1304), tensor(0.3073))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_mean,train_std = x_train.mean(),x_train.std()\n",
    "train_mean,train_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = normalize(x_train, train_mean, train_std)\n",
    "# NB: Use training, not validation mean for validation set\n",
    "x_valid = normalize(x_valid, train_mean, train_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-9.3644e-07), tensor(1.))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_mean,train_std = x_train.mean(),x_train.std()\n",
    "train_mean,train_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def test_near_zero(a, tol=1e-3): \n",
    "    assert a.abs() < tol \n",
    "    print(f\"Near zero: {a}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Near zero: -9.364412107970566e-07\n",
      "Near zero: 0.0\n"
     ]
    }
   ],
   "source": [
    "test_near_zero(x_train.mean())\n",
    "test_near_zero(1-x_train.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 784, tensor(10))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training set has 50000 images, every image is 28x28=784 pixels, images are numbers from 1 to 9\n",
    "n, m = x_train.shape\n",
    "c = y_train.max() + 1\n",
    "n, m, c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Foundations version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num hidden. so input layer=784, hidden layer=50, output layer=1\n",
    "nh = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simplified kaiming init / he init\n",
    "w1 = torch.randn(m,nh)/math.sqrt(m)\n",
    "b1 = torch.zeros(nh)\n",
    "w2 = torch.randn(nh,1)/math.sqrt(nh)\n",
    "b2 = torch.zeros(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.randn(m, n) give a matrix with 0 mean and deviation of 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([784, 50]),\n",
       " tensor([ 0.0253,  0.0170,  0.0105,  0.0187,  0.0569,  0.0011,  0.0092,  0.0129,\n",
       "         -0.0029, -0.0409, -0.0534,  0.0125,  0.0562,  0.0256,  0.0336, -0.0440,\n",
       "         -0.0107, -0.0218,  0.0119, -0.0160, -0.0483, -0.0029, -0.0078, -0.0485,\n",
       "          0.0270, -0.0603,  0.0510, -0.0326,  0.0234, -0.0461, -0.0156, -0.0357,\n",
       "          0.0077, -0.0252, -0.0508, -0.0418,  0.0008, -0.0621,  0.0015, -0.0278,\n",
       "         -0.0282,  0.0300,  0.0224, -0.0311,  0.0218, -0.1446, -0.0224,  0.0326,\n",
       "         -0.0193, -0.0085]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([50]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0.]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([50, 1]), tensor([[-0.1539],\n",
       "         [-0.1221],\n",
       "         [ 0.0577],\n",
       "         [ 0.0694],\n",
       "         [-0.0139]]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([1]), tensor([0.]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1.shape, w1[0]\n",
    "b1.shape, b1\n",
    "w2.shape, w2[:5]\n",
    "b2.shape, b2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### why do we want the mean of weight is 0 and standard deviation is $\\frac{1} {\\sqrt{m}}$? because we used kaiming initialization. dividing the random numbers by square root of m.\n",
    "in fact, we have an activation function as well. so we really want is the std of activation is about 1. we intialzied with   $\\frac{2} {\\sqrt{m}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Near zero: 5.4643245675833896e-05\n",
      "Near zero: -0.00024520978331565857\n"
     ]
    }
   ],
   "source": [
    "test_near_zero(w1.mean())\n",
    "test_near_zero(w1.std()-1/math.sqrt(m))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-0.0059), tensor(0.9924))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This should be ~ (0,1) (mean,std)... because we normalized x_valid with trian_mean and train_std\n",
    "x_valid.mean(),x_valid.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lin(x, w, b): \n",
    "    return x@w + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 784])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 50])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_valid.shape\n",
    "\n",
    "t = lin(x_valid, w1, b1)\n",
    "\n",
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0171), tensor(0.9935))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#...so should this, because we used kaiming init, which is designed to do this\n",
    "t.mean(),t.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x): \n",
    "    return x.clamp_min(0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = relu(lin(x_valid, w1, b1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.3981), tensor(0.5880))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#...actually it really should be this! after Relu, we removed all negative values, so mean will not be 0, std should about halved.\n",
    "t.mean(),t.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From pytorch docs: `a: the negative slope of the rectifier used after this layer (0 for ReLU by default)`\n",
    "\n",
    "$$\\text{std} = \\sqrt{\\frac{2}{(1 + a^2) \\times \\text{fan_in}}}$$\n",
    "\n",
    "This was introduced in the paper that described the Imagenet-winning approach from *He et al*: [Delving Deep into Rectifiers](https://arxiv.org/abs/1502.01852), which was also the first paper that claimed \"super-human performance\" on Imagenet (and, most importantly, it introduced resnets!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kaiming init / he init for relu\n",
    "w1 = torch.randn(m,nh)*math.sqrt(2/m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-0.0001), tensor(0.0504))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# std of w1 is not 1 any more\n",
    "w1.mean(),w1.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.6028), tensor(0.8429))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = relu(lin(x_valid, w1, b1))\n",
    "t.mean(),t.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from torch.nn import init"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "preserves the magnitude of the variance of the weights when initializing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0841, -0.0757,  0.0372,  ..., -0.0235,  0.0200,  0.0039],\n",
       "        [ 0.0251,  0.0842,  0.0565,  ..., -0.0455, -0.0196, -0.0092],\n",
       "        [-0.0546, -0.0227, -0.0484,  ...,  0.0280,  0.0124,  0.0271],\n",
       "        ...,\n",
       "        [-0.0276, -0.0668, -0.0096,  ...,  0.0115,  0.0279, -0.0433],\n",
       "        [-0.0592,  0.0216,  0.0495,  ...,  0.0600, -0.0462, -0.0582],\n",
       "        [ 0.0022, -0.0403,  0.0101,  ..., -0.0109, -0.0835, -0.0089]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1 = torch.zeros(m,nh)\n",
    "init.kaiming_normal_(w1, mode='fan_out')\n",
    "t = relu(lin(x_valid, w1, b1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "init.kaiming_normal_??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$   \\text{std} = \\sqrt{\\frac{2}{(1 + a^2) \\times \\text{fan\\_in}}}$\n",
    "\n",
    "Also known as He initialization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-0.0002), tensor(0.0507))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1.mean(),w1.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10000, 50]), tensor(0.6473), tensor(0.8692))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.shape, t.mean(),t.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 784])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0299,  0.0229, -0.0029,  ..., -0.0112,  0.0027, -0.0341],\n",
       "        [ 0.0230, -0.0118,  0.0102,  ...,  0.0350, -0.0088,  0.0315],\n",
       "        [-0.0318, -0.0131, -0.0161,  ..., -0.0303, -0.0017, -0.0127],\n",
       "        ...,\n",
       "        [ 0.0005, -0.0251,  0.0146,  ...,  0.0030, -0.0246,  0.0308],\n",
       "        [ 0.0059, -0.0092, -0.0206,  ...,  0.0073, -0.0171, -0.0215],\n",
       "        [ 0.0339,  0.0340,  0.0113,  ...,  0.0161,  0.0134,  0.0042]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.Linear(m,nh).weight.shape\n",
    "torch.nn.Linear(m,nh).weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.nn.Linear.forward??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.nn.functional.linear??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.nn.Conv2d??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.nn.modules.conv._ConvNd.reset_parameters??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what if...?\n",
    "def relu(x): \n",
    "    return x.clamp_min(0.) - 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0389), tensor(0.8003))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# kaiming init / he init for relu\n",
    "w1 = torch.randn(m,nh)*math.sqrt(2./m )\n",
    "t1 = relu(lin(x_valid, w1, b1))\n",
    "t1.mean(),t1.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(7.5220e-05), tensor(0.0504))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1.mean(), w1.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(xb):\n",
    "    # xb is the input matrix, e.g. num_images X pixels\n",
    "    l1 = lin(xb, w1, b1)\n",
    "    l2 = relu(l1)\n",
    "    l3 = lin(l2, w2, b2)\n",
    "    return l3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 1])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(x_valid).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.13 ms ± 205 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 10 _ = model(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert model(x_valid).shape == torch.Size([x_valid.shape[0],1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the above all makes sense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss function: MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 1])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(x_valid).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need `squeeze()` to get rid of that trailing (,1), in order to use `mse`. (Of course, `mse` is not a suitable loss function for multi-class classification; we'll use a better loss function soon. We'll use `mse` for now to keep things simple.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def mse(output, targ): \n",
    "    return (output.squeeze(-1) - targ).pow(2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train, y_valid = y_train.float(), y_valid.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction is the output layer, not the mse\n",
    "preds = model(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50000, 1])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50000, 1])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.4767],\n",
       "        [0.0870]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([50000])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.4767, 0.0870])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape\n",
    "preds[:2]\n",
    "preds.squeeze(-1).shape\n",
    "preds.squeeze(-1)[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(29.8744)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse(preds, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([50000, 1]), tensor([[ 0.4767],\n",
       "         [ 0.0870],\n",
       "         [-0.2929],\n",
       "         ...,\n",
       "         [ 0.2838],\n",
       "         [-1.0049],\n",
       "         [-0.0289]]))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([5., 0., 4.,  ..., 8., 4., 8.])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape, preds\n",
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradients and backward pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\operatorname{MSE}=\\frac{1}{n}\\sum_{i=1}^n(Y_i-\\hat{Y_i})^2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_grad(inp, targ): \n",
    "    # grad of loss with respect to output of previous layer\n",
    "    # in this case the inp is the 50000 predictions, so the gradient of loss is with respect to each of the predictions.\n",
    "    inp.g = 2. * (inp.squeeze() - targ).unsqueeze(-1) / inp.shape[0]\n",
    "    print('mse grad', inp.g.shape, inp.g, inp.shape, inp, targ.shape, targ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### no magical here, just the prediction error times 2 and then divided by total number of predictions, so the gradient is for each of the 50000 predictions. mse_grad returns 50000 grads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse grad torch.Size([50000, 1]) tensor([[-1.8093e-04],\n",
      "        [ 3.4793e-06],\n",
      "        [-1.7172e-04],\n",
      "        ...,\n",
      "        [-3.0865e-04],\n",
      "        [-2.0020e-04],\n",
      "        [-3.2116e-04]]) torch.Size([50000, 1]) tensor([[ 0.4767],\n",
      "        [ 0.0870],\n",
      "        [-0.2929],\n",
      "        ...,\n",
      "        [ 0.2838],\n",
      "        [-1.0049],\n",
      "        [-0.0289]]) torch.Size([50000]) tensor([5., 0., 4.,  ..., 8., 4., 8.])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.000180932"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "3.4799999999999997e-06"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_grad(preds, y_train)\n",
    "# the gradients for the first two predictions are: \n",
    "2 * (0.4767 - 5)/50000\n",
    "2 * (0.0870 - 0)/50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.8093e-04],\n",
       "        [ 3.4793e-06],\n",
       "        [-1.7172e-04],\n",
       "        ...,\n",
       "        [-3.0865e-04],\n",
       "        [-2.0020e-04],\n",
       "        [-3.2116e-04]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the gradient is store in the g attribute\n",
    "preds.g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu_grad(inp, out):\n",
    "    # grad of relu with respect to input activations\n",
    "    # this out.g is the gradient of mse inp.g\n",
    "#     print('relu gradient')\n",
    "#     print('out is:', out.shape, out)\n",
    "#     print('out.g is:', out.g.shape, out.g)\n",
    "    # directly pass the gradients to inp from out for all positive inputs, negative inputs get 0 gradient\n",
    "    inp.g = (inp>0).float() * out.g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relu_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lin_grad(inp, out, w, b):   \n",
    "    inp.g = out.g @ w.t()\n",
    "    w.g = (inp.unsqueeze(-1) * out.g.unsqueeze(1)).sum(0)    \n",
    "    b.g = out.g.sum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lin_grad(inp, out, w, b):\n",
    "    # think the gradient process as between two layers\n",
    "    # grad of matmul with respect to input\n",
    "    # out.g is the gradient of next layer, for lin2, out.g is the prediciton gradients calculated by mse_grad\n",
    "    # pass the gradients from next layer to previous layer by multiplying the gradient for each image and its corresponding weight\n",
    "    # image1's gradients for all 50 hidden neurons are just image1's gradient from next layer times each individual weight correspnding to each neuron \n",
    "    inp.g = out.g @ w.t()\n",
    "#     print('nnnnn', out.g[0] * w, inp.g[:1])\n",
    "#     test_near((out.g[0] * w), inp.g[:1].squeeze().unsqueeze(-1))\n",
    "#     w.g = (inp.unsqueeze(-1) * out.g.unsqueeze(1)).sum(0) # why not -1 for out.g\n",
    "    # element_wise multiplication and then sum over all images, input squeeze in a third axis, but gradients from next\n",
    "    # layer squeeze in a second dimension, so the weight gradient dimension is input 2nd dim x gradient 3rd dim, 784x50 in this case.\n",
    "    # gradient for weight connecting first input and first neuron is the sum of first pixel * gradient from first neuron over all images\n",
    "    w.g = (inp.unsqueeze(-1) * out.g.unsqueeze(1)).sum(0)\n",
    "#     print('mmmm', (inp.unsqueeze(-1) * out.g.unsqueeze(1)).shape, w.g.shape)\n",
    "    # bias gradient is just the sum of next layer's gradidents for all images\n",
    "    b.g = out.g.sum(0)\n",
    "#     print('linear layer gradient')\n",
    "#     print('out is:', out.shape, out)\n",
    "#     print('w.g:', w.g.shape, w.g, w.shape, w) \n",
    "#     print('b.g', b.g.shape, b.g, b.shape, b) \n",
    "#     print('inp.g', inp.g.shape, inp.g, inp.shape, inp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### how do we actually back pass loss\n",
    "assuming input layer=1000, hidden layer=9, output layer =3, training images=20000\n",
    "* weight gradient (linear layer): squeeze in a trailing aixs in input, squeeze in a second axis in gradients of next layer, times them together and then sum over all the training examples. back pass the last two layers: (20000, 9, 1)X(20000, 1, 2), so weights are (9,2). it is like the activation of first neuron in hidden layer times the first gradient in the output layer for all images and then sum over them.\n",
    "* bias gradient: sum over all images for the gradients in the next layer\n",
    "* previous layer gradient: gradients of next layer times transposed weights. (20000, 2)x(2, 9)=(20000, 9), this is weighted sum of gradients of next layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_and_backward(inp, targ):\n",
    "    # forward pass:\n",
    "    l1 = inp @ w1 + b1\n",
    "    l2 = relu(l1)\n",
    "#     print('xxxx', l2.shape, l2.unsqueeze(-1).shape, l2[:2])\n",
    "    out = l2 @ w2 + b2\n",
    "    \n",
    "    # we don't actually need the loss in backward!\n",
    "    loss = mse(out, targ)\n",
    "    \n",
    "    # backward pass:\n",
    "    mse_grad(out, targ)\n",
    "#     print('yyy', out.shape, out.g.shape, out.g.unsqueeze(1).shape, out.g[:2])\n",
    "    lin_grad(l2, out, w2, b2)\n",
    "#     print('zzzz', w2.g.shape, l2.g)\n",
    "#     print('yyy', l2.shape, l2.g.shape, l2.g[:2])\n",
    "    relu_grad(l1, l2)\n",
    "#     print('zzz', l1.shape, l1[:2], l1.g.shape, l1.g)\n",
    "    print('yyy', l1.shape, l1.g.shape, l1.g.unsqueeze(1).shape, l1.g[:2], l1.g.unsqueeze(1)[:2])\n",
    "    print('YYY', inp.shape, inp.unsqueeze(-1).shape, inp.unsqueeze(-1)[:2])\n",
    "    lin_grad(inp, l1, w1, b1)\n",
    "    print('zzzz', w1.g.shape, l1.g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse grad torch.Size([50000, 1]) tensor([[-1.8093e-04],\n",
      "        [ 3.4793e-06],\n",
      "        [-1.7172e-04],\n",
      "        ...,\n",
      "        [-3.0865e-04],\n",
      "        [-2.0020e-04],\n",
      "        [-3.2116e-04]]) torch.Size([50000, 1]) tensor([[ 0.4767],\n",
      "        [ 0.0870],\n",
      "        [-0.2929],\n",
      "        ...,\n",
      "        [ 0.2838],\n",
      "        [-1.0049],\n",
      "        [-0.0289]]) torch.Size([50000]) tensor([5., 0., 4.,  ..., 8., 4., 8.])\n",
      "yyy torch.Size([50000, 50]) torch.Size([50000, 50]) torch.Size([50000, 1, 50]) tensor([[ 2.7842e-05,  0.0000e+00, -1.0446e-05, -0.0000e+00,  2.5195e-06,\n",
      "          0.0000e+00,  2.0967e-06, -2.4934e-06, -4.9826e-06, -0.0000e+00,\n",
      "         -1.2084e-05, -6.0460e-05, -2.6124e-05, -0.0000e+00, -1.4225e-05,\n",
      "          8.4178e-06, -1.0181e-05,  0.0000e+00, -0.0000e+00,  3.8999e-06,\n",
      "          0.0000e+00,  1.3938e-05,  5.5831e-06, -6.0686e-05,  3.1782e-05,\n",
      "          2.2215e-05,  0.0000e+00,  2.3160e-05, -0.0000e+00, -0.0000e+00,\n",
      "          0.0000e+00, -9.9402e-06,  0.0000e+00,  0.0000e+00,  2.0387e-05,\n",
      "         -1.1116e-05, -0.0000e+00, -2.9485e-05,  0.0000e+00,  0.0000e+00,\n",
      "         -0.0000e+00, -0.0000e+00,  4.6323e-06,  0.0000e+00, -5.0821e-06,\n",
      "         -0.0000e+00, -0.0000e+00,  0.0000e+00,  0.0000e+00, -0.0000e+00],\n",
      "        [-0.0000e+00, -4.2471e-07,  2.0088e-07,  0.0000e+00, -4.8450e-08,\n",
      "         -0.0000e+00, -4.0320e-08,  4.7948e-08,  0.0000e+00,  5.6763e-07,\n",
      "          0.0000e+00,  1.1626e-06,  0.0000e+00,  1.8555e-08,  0.0000e+00,\n",
      "         -1.6187e-07,  0.0000e+00, -0.0000e+00,  8.3112e-07, -0.0000e+00,\n",
      "         -0.0000e+00, -2.6802e-07, -0.0000e+00,  0.0000e+00, -6.1116e-07,\n",
      "         -4.2718e-07, -0.0000e+00, -4.4536e-07,  1.7936e-08,  0.0000e+00,\n",
      "         -2.4089e-07,  0.0000e+00, -0.0000e+00, -5.5698e-07, -3.9204e-07,\n",
      "          0.0000e+00,  0.0000e+00,  5.6698e-07, -0.0000e+00, -0.0000e+00,\n",
      "          5.6709e-07,  0.0000e+00, -8.9077e-08, -0.0000e+00,  9.7728e-08,\n",
      "          3.2467e-07,  0.0000e+00, -0.0000e+00, -3.9666e-07,  2.2242e-08]]) tensor([[[ 2.7842e-05,  0.0000e+00, -1.0446e-05, -0.0000e+00,  2.5195e-06,\n",
      "           0.0000e+00,  2.0967e-06, -2.4934e-06, -4.9826e-06, -0.0000e+00,\n",
      "          -1.2084e-05, -6.0460e-05, -2.6124e-05, -0.0000e+00, -1.4225e-05,\n",
      "           8.4178e-06, -1.0181e-05,  0.0000e+00, -0.0000e+00,  3.8999e-06,\n",
      "           0.0000e+00,  1.3938e-05,  5.5831e-06, -6.0686e-05,  3.1782e-05,\n",
      "           2.2215e-05,  0.0000e+00,  2.3160e-05, -0.0000e+00, -0.0000e+00,\n",
      "           0.0000e+00, -9.9402e-06,  0.0000e+00,  0.0000e+00,  2.0387e-05,\n",
      "          -1.1116e-05, -0.0000e+00, -2.9485e-05,  0.0000e+00,  0.0000e+00,\n",
      "          -0.0000e+00, -0.0000e+00,  4.6323e-06,  0.0000e+00, -5.0821e-06,\n",
      "          -0.0000e+00, -0.0000e+00,  0.0000e+00,  0.0000e+00, -0.0000e+00]],\n",
      "\n",
      "        [[-0.0000e+00, -4.2471e-07,  2.0088e-07,  0.0000e+00, -4.8450e-08,\n",
      "          -0.0000e+00, -4.0320e-08,  4.7948e-08,  0.0000e+00,  5.6763e-07,\n",
      "           0.0000e+00,  1.1626e-06,  0.0000e+00,  1.8555e-08,  0.0000e+00,\n",
      "          -1.6187e-07,  0.0000e+00, -0.0000e+00,  8.3112e-07, -0.0000e+00,\n",
      "          -0.0000e+00, -2.6802e-07, -0.0000e+00,  0.0000e+00, -6.1116e-07,\n",
      "          -4.2718e-07, -0.0000e+00, -4.4536e-07,  1.7936e-08,  0.0000e+00,\n",
      "          -2.4089e-07,  0.0000e+00, -0.0000e+00, -5.5698e-07, -3.9204e-07,\n",
      "           0.0000e+00,  0.0000e+00,  5.6698e-07, -0.0000e+00, -0.0000e+00,\n",
      "           5.6709e-07,  0.0000e+00, -8.9077e-08, -0.0000e+00,  9.7728e-08,\n",
      "           3.2467e-07,  0.0000e+00, -0.0000e+00, -3.9666e-07,  2.2242e-08]]])\n",
      "YYY torch.Size([50000, 784]) torch.Size([50000, 784, 1]) tensor([[[-0.4245],\n",
      "         [-0.4245],\n",
      "         [-0.4245],\n",
      "         ...,\n",
      "         [-0.4245],\n",
      "         [-0.4245],\n",
      "         [-0.4245]],\n",
      "\n",
      "        [[-0.4245],\n",
      "         [-0.4245],\n",
      "         [-0.4245],\n",
      "         ...,\n",
      "         [-0.4245],\n",
      "         [-0.4245],\n",
      "         [-0.4245]]])\n",
      "zzzz torch.Size([784, 50]) tensor([[ 2.7842e-05,  0.0000e+00, -1.0446e-05,  ...,  0.0000e+00,\n",
      "          0.0000e+00, -0.0000e+00],\n",
      "        [-0.0000e+00, -4.2471e-07,  2.0088e-07,  ..., -0.0000e+00,\n",
      "         -3.9666e-07,  2.2242e-08],\n",
      "        [ 0.0000e+00,  0.0000e+00, -9.9142e-06,  ...,  0.0000e+00,\n",
      "          0.0000e+00, -1.0977e-06],\n",
      "        ...,\n",
      "        [ 0.0000e+00,  0.0000e+00, -1.7820e-05,  ...,  0.0000e+00,\n",
      "          0.0000e+00, -1.9731e-06],\n",
      "        [ 3.0806e-05,  0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
      "          2.2824e-05, -0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00, -1.8542e-05,  ...,  0.0000e+00,\n",
      "          0.0000e+00, -0.0000e+00]])\n"
     ]
    }
   ],
   "source": [
    "forward_and_backward(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1]],\n",
       "\n",
       "        [[1]]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 3, 1]), tensor([[[1],\n",
       "          [2],\n",
       "          [3]],\n",
       " \n",
       "         [[4],\n",
       "          [5],\n",
       "          [6]]]))"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 1, 1]), tensor([[[5]],\n",
       " \n",
       "         [[1]]]))"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 3, 1]), tensor([[[ 5],\n",
       "          [10],\n",
       "          [15]],\n",
       " \n",
       "         [[ 4],\n",
       "          [ 5],\n",
       "          [ 6]]]))"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 9],\n",
       "        [15],\n",
       "        [21]])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[30],\n",
       "        [15]])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 5, 10, 15],\n",
       "        [ 4,  5,  6]])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# element-wise multiplication\n",
    "a = torch.tensor([[1,2,3], [4,5,6]]).unsqueeze(-1)\n",
    "b = torch.tensor([[5], [1]]).unsqueeze(1)\n",
    "# b == torch.tensor([[5], [1]]).unsqueeze(-1)\n",
    "#a @ b give a error because shape mismatch\n",
    "a.shape, a\n",
    "b.shape, b\n",
    "c = a * b # broadcasting\n",
    "c.shape, c\n",
    "c.sum(0)\n",
    "c.sum(1)\n",
    "c.sum(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.000202124"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "4.0200000000000005e-06"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate mse gradient 2/num_of_input_images * (activation of l2 which is the prediction - target which is the handwritten number)\n",
    "2/50000*(-0.0531 - 5) # gradient from first image in x_train\n",
    "2/50000*(0.1005 - 0)  # gradient from second image in x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50000, 784])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4245, -0.4245, -0.4245,  ..., -0.4245, -0.4245, -0.4245],\n",
       "        [-0.4245, -0.4245, -0.4245,  ..., -0.4245, -0.4245, -0.4245],\n",
       "        [-0.4245, -0.4245, -0.4245,  ..., -0.4245, -0.4245, -0.4245],\n",
       "        ...,\n",
       "        [-0.4245, -0.4245, -0.4245,  ..., -0.4245, -0.4245, -0.4245],\n",
       "        [-0.4245, -0.4245, -0.4245,  ..., -0.4245, -0.4245, -0.4245],\n",
       "        [-0.4245, -0.4245, -0.4245,  ..., -0.4245, -0.4245, -0.4245]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([5., 0., 4., 1., 9., 2., 1., 3., 1., 4.])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse grad torch.Size([50000, 1]) tensor([[-2.0213e-04],\n",
      "        [ 4.0215e-06],\n",
      "        [-1.8602e-04],\n",
      "        ...,\n",
      "        [-3.1210e-04],\n",
      "        [-1.3147e-04],\n",
      "        [-2.9066e-04]]) torch.Size([50000, 1]) tensor([[-0.0531],\n",
      "        [ 0.1005],\n",
      "        [-0.6504],\n",
      "        ...,\n",
      "        [ 0.1976],\n",
      "        [ 0.7133],\n",
      "        [ 0.7335]]) torch.Size([50000]) tensor([5., 0., 4.,  ..., 8., 4., 8.])\n",
      "out is: torch.Size([50000, 1]) tensor([[-0.0531],\n",
      "        [ 0.1005],\n",
      "        [-0.6504],\n",
      "        ...,\n",
      "        [ 0.1976],\n",
      "        [ 0.7133],\n",
      "        [ 0.7335]])\n",
      "w.g: torch.Size([50, 1]) tensor([[-4.6058],\n",
      "        [ 1.1992],\n",
      "        [-4.0051],\n",
      "        [-0.3161],\n",
      "        [-7.8630],\n",
      "        [ 3.4794],\n",
      "        [ 3.3173],\n",
      "        [-4.2022],\n",
      "        [-5.9368],\n",
      "        [ 2.7553],\n",
      "        [ 1.3928],\n",
      "        [-1.4530],\n",
      "        [-2.9946],\n",
      "        [-3.2554],\n",
      "        [-2.1126],\n",
      "        [ 2.5994],\n",
      "        [-3.0389],\n",
      "        [ 1.0889],\n",
      "        [ 1.6581],\n",
      "        [ 1.7819],\n",
      "        [ 3.6775],\n",
      "        [ 3.2682],\n",
      "        [ 1.5561],\n",
      "        [ 1.3155],\n",
      "        [ 1.2489],\n",
      "        [-0.4200],\n",
      "        [-1.1060],\n",
      "        [ 1.1753],\n",
      "        [-1.1555],\n",
      "        [-4.0056],\n",
      "        [-8.3169],\n",
      "        [-3.1210],\n",
      "        [-6.3270],\n",
      "        [ 2.2784],\n",
      "        [ 2.6680],\n",
      "        [-0.8471],\n",
      "        [-4.6580],\n",
      "        [-0.2393],\n",
      "        [ 1.6283],\n",
      "        [ 3.6311],\n",
      "        [ 2.3783],\n",
      "        [-2.2353],\n",
      "        [ 0.6153],\n",
      "        [-7.2345],\n",
      "        [-2.7786],\n",
      "        [ 3.7287],\n",
      "        [-0.4977],\n",
      "        [ 2.1640],\n",
      "        [ 1.6461],\n",
      "        [ 0.8095]]) torch.Size([50, 1]) tensor([[-0.0318],\n",
      "        [ 0.0501],\n",
      "        [ 0.0479],\n",
      "        [ 0.0857],\n",
      "        [-0.1075],\n",
      "        [-0.0272],\n",
      "        [-0.1335],\n",
      "        [-0.1502],\n",
      "        [ 0.0149],\n",
      "        [-0.3313],\n",
      "        [ 0.2465],\n",
      "        [-0.1763],\n",
      "        [-0.3160],\n",
      "        [-0.2819],\n",
      "        [ 0.0975],\n",
      "        [-0.0011],\n",
      "        [-0.0282],\n",
      "        [-0.0941],\n",
      "        [ 0.1924],\n",
      "        [-0.1108],\n",
      "        [ 0.0344],\n",
      "        [ 0.2147],\n",
      "        [-0.2199],\n",
      "        [-0.0442],\n",
      "        [ 0.2128],\n",
      "        [ 0.2452],\n",
      "        [-0.0301],\n",
      "        [-0.0005],\n",
      "        [-0.1337],\n",
      "        [-0.0899],\n",
      "        [-0.0061],\n",
      "        [-0.0157],\n",
      "        [-0.0168],\n",
      "        [-0.1865],\n",
      "        [-0.1000],\n",
      "        [ 0.1252],\n",
      "        [ 0.0575],\n",
      "        [ 0.0024],\n",
      "        [ 0.2411],\n",
      "        [-0.1553],\n",
      "        [-0.2363],\n",
      "        [-0.1420],\n",
      "        [ 0.0206],\n",
      "        [ 0.0304],\n",
      "        [-0.1316],\n",
      "        [-0.0129],\n",
      "        [ 0.1918],\n",
      "        [ 0.0520],\n",
      "        [ 0.1353],\n",
      "        [ 0.1010]])\n",
      "b.g torch.Size([1]) tensor([-9.1935]) torch.Size([1]) tensor([0.])\n",
      "inp.g torch.Size([50000, 50]) tensor([[ 6.4180e-06, -1.0136e-05, -9.6917e-06,  ..., -1.0520e-05,\n",
      "         -2.7345e-05, -2.0407e-05],\n",
      "        [-1.2769e-07,  2.0168e-07,  1.9283e-07,  ...,  2.0930e-07,\n",
      "          5.4405e-07,  4.0602e-07],\n",
      "        [ 5.9066e-06, -9.3287e-06, -8.9194e-06,  ..., -9.6814e-06,\n",
      "         -2.5165e-05, -1.8781e-05],\n",
      "        ...,\n",
      "        [ 9.9100e-06, -1.5652e-05, -1.4965e-05,  ..., -1.6243e-05,\n",
      "         -4.2222e-05, -3.1510e-05],\n",
      "        [ 4.1745e-06, -6.5931e-06, -6.3039e-06,  ..., -6.8424e-06,\n",
      "         -1.7786e-05, -1.3273e-05],\n",
      "        [ 9.2293e-06, -1.4577e-05, -1.3937e-05,  ..., -1.5128e-05,\n",
      "         -3.9322e-05, -2.9346e-05]]) torch.Size([50000, 50]) tensor([[ 1.6690,  0.2940,  1.0946,  ...,  1.7337, -0.5000, -0.5000],\n",
      "        [ 2.7264,  0.4280,  0.8987,  ...,  0.4824,  0.8926, -0.5000],\n",
      "        [-0.5000, -0.2271, -0.5000,  ..., -0.5000, -0.5000, -0.5000],\n",
      "        ...,\n",
      "        [ 0.5432, -0.5000,  2.1636,  ...,  0.2401, -0.5000, -0.5000],\n",
      "        [-0.5000, -0.5000, -0.3800,  ..., -0.0662,  0.8863,  1.4716],\n",
      "        [-0.5000, -0.5000,  0.4912,  ..., -0.5000,  0.1048, -0.5000]])\n",
      "out is: torch.Size([50000, 50]) tensor([[ 2.1690,  0.7940,  1.5946,  ...,  2.2337, -0.4480, -0.6142],\n",
      "        [ 3.2264,  0.9280,  1.3987,  ...,  0.9824,  1.3926, -0.9845],\n",
      "        [-0.4311,  0.2729, -0.8945,  ..., -0.7116, -2.4284, -1.3981],\n",
      "        ...,\n",
      "        [ 1.0432, -0.5655,  2.6636,  ...,  0.7401, -1.6903, -1.2903],\n",
      "        [-0.4066, -1.3283,  0.1200,  ...,  0.4338,  1.3863,  1.9716],\n",
      "        [-0.0037, -3.0170,  0.9912,  ..., -0.9017,  0.6048, -1.1838]])\n",
      "w.g: torch.Size([784, 50]) tensor([[-0.0998,  0.0701,  0.1325,  ...,  0.0691,  0.2021,  0.1579],\n",
      "        [-0.0998,  0.0701,  0.1325,  ...,  0.0691,  0.2021,  0.1579],\n",
      "        [-0.0998,  0.0701,  0.1325,  ...,  0.0691,  0.2021,  0.1579],\n",
      "        ...,\n",
      "        [-0.0998,  0.0701,  0.1325,  ...,  0.0691,  0.2021,  0.1579],\n",
      "        [-0.0998,  0.0701,  0.1325,  ...,  0.0691,  0.2021,  0.1579],\n",
      "        [-0.0998,  0.0701,  0.1325,  ...,  0.0691,  0.2021,  0.1579]]) torch.Size([784, 50]) tensor([[ 0.0940,  0.0374, -0.0631,  ...,  0.0064,  0.0244,  0.0592],\n",
      "        [-0.1508,  0.0165,  0.0210,  ..., -0.0877, -0.0055, -0.0326],\n",
      "        [-0.0295,  0.0832, -0.1161,  ..., -0.0944,  0.0313, -0.0245],\n",
      "        ...,\n",
      "        [-0.0367, -0.0455,  0.0193,  ...,  0.0334, -0.0294, -0.0047],\n",
      "        [ 0.0785, -0.0051,  0.0537,  ..., -0.0066,  0.0225, -0.0091],\n",
      "        [ 0.0733, -0.0081,  0.0796,  ...,  0.0226, -0.0717, -0.0017]])\n",
      "b.g torch.Size([50]) tensor([ 2.3514e-01, -1.6503e-01, -3.1223e-01, -5.0595e-01,  8.1025e-01,\n",
      "         4.6829e-02,  2.8911e-01,  9.8923e-01, -1.0841e-01,  9.4219e-01,\n",
      "        -8.7867e-01,  9.8593e-01,  2.0871e+00,  1.9588e+00, -5.2639e-01,\n",
      "         2.7515e-03,  1.6707e-01,  3.0092e-01, -7.2756e-01,  4.2674e-01,\n",
      "        -5.3504e-02, -4.4656e-01,  7.8487e-01,  2.0299e-01, -7.5950e-01,\n",
      "        -1.3857e+00,  1.7490e-01,  1.8229e-03,  7.5632e-01,  5.8546e-01,\n",
      "         4.8977e-02,  1.0404e-01,  1.3474e-01,  5.7521e-01,  2.8535e-01,\n",
      "        -6.9678e-01, -3.8627e-01, -1.1023e-02, -8.1011e-01,  2.2861e-01,\n",
      "         7.4785e-01,  9.2885e-01, -1.0021e-01, -2.4350e-01,  8.9962e-01,\n",
      "         2.1526e-02, -9.3200e-01, -1.6275e-01, -4.7610e-01, -3.7199e-01]) torch.Size([50]) tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.])\n",
      "inp.g torch.Size([50000, 784]) tensor([[ 6.2757e-06, -2.1405e-06,  9.0186e-08,  ..., -4.5773e-06,\n",
      "         -8.0871e-06, -1.3677e-05],\n",
      "        [ 1.7813e-07,  2.3828e-07,  2.8690e-07,  ...,  2.3865e-07,\n",
      "          5.0685e-08,  1.3885e-07],\n",
      "        [-5.4825e-06, -4.2699e-06, -8.6579e-06,  ...,  2.0096e-06,\n",
      "          1.2058e-06, -1.5882e-05],\n",
      "        ...,\n",
      "        [ 1.6156e-06, -9.0796e-06, -1.5128e-05,  ..., -1.2468e-05,\n",
      "         -2.5255e-06, -1.6773e-05],\n",
      "        [ 6.3383e-07, -2.5846e-06, -7.7840e-06,  ..., -1.9168e-06,\n",
      "         -6.6336e-07, -3.0189e-06],\n",
      "        [-1.5062e-06, -2.0315e-05, -2.1685e-05,  ..., -8.0983e-06,\n",
      "         -7.9013e-06, -4.3947e-06]]) torch.Size([50000, 784]) tensor([[-0.4245, -0.4245, -0.4245,  ..., -0.4245, -0.4245, -0.4245],\n",
      "        [-0.4245, -0.4245, -0.4245,  ..., -0.4245, -0.4245, -0.4245],\n",
      "        [-0.4245, -0.4245, -0.4245,  ..., -0.4245, -0.4245, -0.4245],\n",
      "        ...,\n",
      "        [-0.4245, -0.4245, -0.4245,  ..., -0.4245, -0.4245, -0.4245],\n",
      "        [-0.4245, -0.4245, -0.4245,  ..., -0.4245, -0.4245, -0.4245],\n",
      "        [-0.4245, -0.4245, -0.4245,  ..., -0.4245, -0.4245, -0.4245]])\n"
     ]
    }
   ],
   "source": [
    "x_train.shape\n",
    "x_train[:10]\n",
    "y_train[:10]\n",
    "forward_and_backward(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.2419, -0.1247,  0.1506,  ..., -0.0096, -0.1922,  0.0087],\n",
       "         [-0.2419, -0.1247,  0.1506,  ..., -0.0096, -0.1922,  0.0087],\n",
       "         [-0.2419, -0.1247,  0.1506,  ..., -0.0096, -0.1922,  0.0087],\n",
       "         ...,\n",
       "         [-0.2419, -0.1247,  0.1506,  ..., -0.0096, -0.1922,  0.0087],\n",
       "         [-0.2419, -0.1247,  0.1506,  ..., -0.0096, -0.1922,  0.0087],\n",
       "         [-0.2419, -0.1247,  0.1506,  ..., -0.0096, -0.1922,  0.0087]]),\n",
       " torch.Size([784, 50]))"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1.g, w1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save for testing against later\n",
    "w1g = w1.g.clone()\n",
    "w2g = w2.g.clone()\n",
    "b1g = b1.g.clone()\n",
    "b2g = b2.g.clone()\n",
    "ig  = x_train.g.clone()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We cheat a little bit and use PyTorch autograd to check our results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "xt2 = x_train.clone().requires_grad_(True)\n",
    "w12 = w1.clone().requires_grad_(True)\n",
    "w22 = w2.clone().requires_grad_(True)\n",
    "b12 = b1.clone().requires_grad_(True)\n",
    "b22 = b2.clone().requires_grad_(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(inp, targ):\n",
    "    # forward pass:\n",
    "    l1 = inp @ w12 + b12\n",
    "    l2 = relu(l1)\n",
    "    out = l2 @ w22 + b22\n",
    "    # we don't actually need the loss in backward!\n",
    "    return mse(out, targ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = forward(xt2, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_near(w22.grad, w2g)\n",
    "test_near(b22.grad, b2g)\n",
    "test_near(w12.grad, w1g)\n",
    "test_near(b12.grad, b1g)\n",
    "test_near(xt2.grad, ig )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refactor model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layers as classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Relu():\n",
    "    def __call__(self, inp):\n",
    "        self.inp = inp\n",
    "        self.out = inp.clamp_min(0.)-0.5\n",
    "        return self.out\n",
    "    \n",
    "    def backward(self): \n",
    "        self.inp.g = (self.inp>0).float() * self.out.g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lin():\n",
    "    def __init__(self, w, b): \n",
    "        self.w = w\n",
    "        self.b = b\n",
    "        \n",
    "    def __call__(self, inp):\n",
    "        self.inp = inp\n",
    "        self.out = inp @ self.w + self.b\n",
    "        return self.out\n",
    "    \n",
    "    def backward(self):\n",
    "        self.inp.g = self.out.g @ self.w.t()\n",
    "        # Creating a giant outer product, just to sum it, is inefficient!\n",
    "        self.w.g = (self.inp.unsqueeze(-1) * self.out.g.unsqueeze(1)).sum(0)\n",
    "        self.b.g = self.out.g.sum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mse():\n",
    "    def __call__(self, inp, targ):\n",
    "        self.inp = inp\n",
    "        self.targ = targ\n",
    "        self.out = (inp.squeeze() - targ).pow(2).mean()\n",
    "        return self.out\n",
    "    \n",
    "    def backward(self):\n",
    "        self.inp.g = 2. * (self.inp.squeeze() - self.targ).unsqueeze(-1) / self.targ.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model():\n",
    "    def __init__(self, w1, b1, w2, b2):\n",
    "        self.layers = [Lin(w1, b1), Relu(), Lin(w2, b2)]\n",
    "        self.loss = Mse()\n",
    "        \n",
    "    def __call__(self, x, targ):\n",
    "        for l in self.layers: \n",
    "            x = l(x)\n",
    "        return self.loss(x, targ)\n",
    "    \n",
    "    def backward(self):\n",
    "        self.loss.backward()\n",
    "        for l in reversed(self.layers): \n",
    "            l.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1.g, b1.g, w2.g, b2.g = [None] * 4\n",
    "model = Model(w1, b1, w2, b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1.g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 465 ms, sys: 1.15 s, total: 1.61 s\n",
      "Wall time: 22.8 ms\n"
     ]
    }
   ],
   "source": [
    "%time loss = model(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(29.8744)"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16.1 s, sys: 1min 24s, total: 1min 41s\n",
      "Wall time: 2.66 s\n"
     ]
    }
   ],
   "source": [
    "%time model.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<__main__.Lin at 0x7fc9d3ff94e0>,\n",
       " <__main__.Relu at 0x7fc9d3ff9e48>,\n",
       " <__main__.Lin at 0x7fc9d3ff9160>]"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_near(w2g, w2.g)\n",
    "test_near(b2g, b2.g)\n",
    "test_near(w1g, w1.g)\n",
    "test_near(b1g, b1.g)\n",
    "test_near(ig, x_train.g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Module.forward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Module():\n",
    "    def __call__(self, *args):\n",
    "        self.args = args\n",
    "        self.out = self.forward(*args)\n",
    "        return self.out\n",
    "    \n",
    "    def forward(self): \n",
    "        raise Exception('not implemented')\n",
    "        \n",
    "    def backward(self): \n",
    "        self.bwd(self.out, *self.args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Relu(Module):\n",
    "    def forward(self, inp): \n",
    "        return inp.clamp_min(0.)-0.5\n",
    "    \n",
    "    def bwd(self, out, inp): \n",
    "        inp.g = (inp > 0).float() * out.g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lin(Module):\n",
    "    def __init__(self, w, b): \n",
    "        self.w = w\n",
    "        self.b = b\n",
    "        \n",
    "    def forward(self, inp): \n",
    "        return inp @ self.w + self.b\n",
    "    \n",
    "    def bwd(self, out, inp):\n",
    "        inp.g = out.g @ self.w.t()\n",
    "        self.w.g = torch.einsum(\"bi,bj->ij\", inp, out.g)\n",
    "        self.b.g = out.g.sum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mse(Module):\n",
    "    def forward (self, inp, targ): \n",
    "        return (inp.squeeze() - targ).pow(2).mean()\n",
    "    \n",
    "    def bwd(self, out, inp, targ): \n",
    "        inp.g = 2*(inp.squeeze()-targ).unsqueeze(-1) / targ.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model():\n",
    "    def __init__(self):\n",
    "        self.layers = [Lin(w1, b1), Relu(), Lin(w2, b2)]\n",
    "        self.loss = Mse()\n",
    "        \n",
    "    def __call__(self, x, targ):\n",
    "        for l in self.layers: \n",
    "            x = l(x)\n",
    "        return self.loss(x, targ)\n",
    "    \n",
    "    def backward(self):\n",
    "        self.loss.backward()\n",
    "        for l in reversed(self.layers): \n",
    "            l.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1.g,b1.g,w2.g,b2.g = [None]*4\n",
    "model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 614 ms, sys: 2.25 s, total: 2.86 s\n",
      "Wall time: 42 ms\n"
     ]
    }
   ],
   "source": [
    "%time loss = model(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.19 s, sys: 1min 30s, total: 1min 34s\n",
      "Wall time: 1.31 s\n"
     ]
    }
   ],
   "source": [
    "%time model.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_near(w2g, w2.g)\n",
    "test_near(b2g, b2.g)\n",
    "test_near(w1g, w1.g)\n",
    "test_near(b1g, b1.g)\n",
    "test_near(ig, x_train.g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without einsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lin(Module):\n",
    "    def __init__(self, w, b): \n",
    "        self.w = w\n",
    "        self.b = b\n",
    "        \n",
    "    def forward(self, inp): \n",
    "        return inp @ self.w + self.b\n",
    "    \n",
    "    def bwd(self, out, inp):\n",
    "        inp.g = out.g @ self.w.t()\n",
    "        self.w.g = inp.t() @ out.g\n",
    "        self.b.g = out.g.sum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1.g,b1.g,w2.g,b2.g = [None]*4\n",
    "model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 707 ms, sys: 2.91 s, total: 3.62 s\n",
      "Wall time: 50.6 ms\n"
     ]
    }
   ],
   "source": [
    "%time loss = model(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.33 s, sys: 8.32 s, total: 11.6 s\n",
      "Wall time: 163 ms\n"
     ]
    }
   ],
   "source": [
    "%time model.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_near(w2g, w2.g)\n",
    "test_near(b2g, b2.g)\n",
    "test_near(w1g, w1.g)\n",
    "test_near(b1g, b1.g)\n",
    "test_near(ig, x_train.g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nn.Linear and nn.Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, n_in, nh, n_out):\n",
    "        super().__init__()\n",
    "        self.layers = [nn.Linear(n_in,nh), nn.ReLU(), nn.Linear(nh,n_out)]\n",
    "        self.loss = mse\n",
    "        \n",
    "    def __call__(self, x, targ):\n",
    "        for l in self.layers: \n",
    "            x = l(x)\n",
    "        return self.loss(x.squeeze(), targ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(m, nh, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 733 ms, sys: 3.73 s, total: 4.46 s\n",
      "Wall time: 74.2 ms\n"
     ]
    }
   ],
   "source": [
    "%time loss = model(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.54 s, sys: 1.89 s, total: 5.43 s\n",
      "Wall time: 76.9 ms\n"
     ]
    }
   ],
   "source": [
    "%time loss.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 02_fully_connected.ipynb to exp/nb_02.py\r\n"
     ]
    }
   ],
   "source": [
    "!python notebook2script.py 02_fully_connected.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
